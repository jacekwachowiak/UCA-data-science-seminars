{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab1_CNN_student.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacekwachowiak/UCA-data-science-seminars/blob/master/Lab1_CNN_student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd322ew3iMg-",
        "colab_type": "text"
      },
      "source": [
        "# Lab 1: Convolutional Neural Networks\n",
        "\n",
        "In this first Lab, we discover a Deep Learning framework (Pytorch), which we use to create our very first CNN (LeNet) and use it to perform handwritten character recognition.\n",
        "\n",
        "This Lab assumes that you are familiar with the Python language. If you're not, please do Lab 0 first: https://colab.research.google.com/drive/16XlCqmmUQvwBD3D5u0lOy1rUFfDDZdYi\n",
        "\n",
        "![alt text](https://camo.githubusercontent.com/d440ac2eee1cb3ea33340a2c5f6f15a0878e9275/687474703a2f2f692e7974696d672e636f6d2f76692f3051493378675875422d512f687164656661756c742e6a7067)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TKgqYn_izjh",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "## What's a CNN?\n",
        "\n",
        "Convolutional Neural Networks are a subclass of Neural Networks that use Convolutional layers. These layers are basically sliding filters and work quite well for vision tasks.\n",
        "\n",
        "![alt text](https://embarc.org/embarc_mli/doc/build/html/_images/image104.jpg)\n",
        "\n",
        "## What's a framework and why are we using one (PyTorch)?\n",
        "\n",
        "A programming framework is a collection of functions and utilities that is ready to use. Modern Deep Learning frameworks contain everything that is needed (layers, optimizers, losses, gradient computation...) to create and use neural networks, and make that really easy.\n",
        "\n",
        "PyTorch, originally created by Facebook, is one of the most used frameworks, especially among researchers. The other most used framework are Tensorflow (created by Google) and Keras (an abstraction layer for multiple frameworks, including Tensorflow). PyTorch has gained a lot of popularity since its 1.0 release in 2018.\n",
        "\n",
        "![alt text](https://miro.medium.com/max/1200/1*s_BwkYxpGv34vjOHi8tDzg.png)\n",
        "\n",
        "## Why use Google Colab and GPUs?\n",
        "\n",
        "Google Colab is a collaborative workspace based on Jupyter Notebook, that lets you use a Python environment on Google Cloud with GPUs, for FREE!\n",
        "\n",
        "GPUs (Graphical Processing Units) are powerful chips that let you train and use neural networks much faster than CPUs. Having access to a GPU is very important for Deep Learning, as it can often make training more than 100x faster. It might not seem that huge at first, but state of the art neural nets can take days to train on common datasets, even with multiple powerful GPUs. On CPUs, it would take **years**.\n",
        "\n",
        "Colab gives you access to a free Nvidia Tesla K80 (most of the time), which is a 1000€ graphics card with 24GB of VRAM.\n",
        "\n",
        "![alt text](https://gitcdn.xyz/cdn/Tony607/blog_statics/b9259799b5bf99efdf761fed8827ff28638c8599/images/colab/pytorch-colab.png)\n",
        "\n",
        "## /!\\ IMPORTANT: Use a GPU Runtime\n",
        "\n",
        "To use a GPU in Colab, go to Runtime -> Change Runtime Type -> Hardware Accelerator -> GPU.\n",
        "\n",
        "**Do this step before running any of the code below, otherwise you will have to run it again.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_bXnm48iqBk",
        "colab_type": "text"
      },
      "source": [
        "## Importing libraries\n",
        "\n",
        "For this lab, we only need PyTorch packages: \"torch\" and \"torchvision\".\n",
        "\n",
        "\"**torch**\" contains the Deep Learning framework itself. \"**torchvision**\" contains datasets, pre-trained models, and image manipulation functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSr0zNgaihYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import Pytorch\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "#Little commonly used shortcut\n",
        "import torch.nn as nn\n",
        "\n",
        "#We need the display function from IPython for Jupyter Notebook/Colab\n",
        "from IPython.display import display\n",
        "\n",
        "#A package to make beautiful progress bars :) \n",
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6tgbmM_jGWl",
        "colab_type": "text"
      },
      "source": [
        "## Downloading the data\n",
        "\n",
        "We are working with the MNIST dataset, which containts handwritten digits.\n",
        "\n",
        "We download the data using torchvision. We get the data in the form of a PyTorch \"Dataset\" object, which is a class that abstracts data loading and that can be iterated like a list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l5Z_sjQjI2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_dataset = torchvision.datasets.MNIST(\".\", train=True, download=True)\n",
        "\n",
        "print(mnist_dataset[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqmrwytQoPPr",
        "colab_type": "text"
      },
      "source": [
        "We see that each element is a tuple containing a PIL Image (Python Imaging Library) and a label (0 here).\n",
        "We can visualize PIL images in Colab using the **display** function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdOLY9ehZj_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display(mnist_dataset[128][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msGnCP0MmWMA",
        "colab_type": "text"
      },
      "source": [
        "# Part 1: Looking at the data\n",
        "\n",
        "In Data Science, it is very important to visualize the data we are working with, in order to understand it better and detect issues."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGRDyNSEY7sd",
        "colab_type": "text"
      },
      "source": [
        "## Q1: Display 10 images with their label\n",
        "\n",
        "Using a Python for loop and the **display** function, show 10 images from the dataset and their labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I45idluXomoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G37azQkZKr9",
        "colab_type": "text"
      },
      "source": [
        "## Q2: Display 10 images from a specific class\n",
        "\n",
        "Using a Python \"for\" loop and conditions (or list comprehensions), display 10 images from a specific class (4, for example)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbZcVa-4YPrU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db-YL3NAZ0R_",
        "colab_type": "text"
      },
      "source": [
        "## Q3: Count the number of elements in each class\n",
        "\n",
        "Using a \"for\" loop, the \"count\" method and the \"print\" function, display the number of elements in each class of the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezQnZ5erZ3ei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6s98Vm-j_wQ",
        "colab_type": "text"
      },
      "source": [
        "# Part 2: Creating a Neural Network with torch.nn\n",
        "\n",
        "For our first CNN, we are going to implement LeNet5, which was used for handwritten digits classification for the first time in 1989 (http://yann.lecun.com/exdb/lenet/).\n",
        "\n",
        "It is common to represent Neural Network architectures using charts such as this one:\n",
        "\n",
        "![alt text](https://miro.medium.com/fit/c/1838/551/0*H9_eGAtkQXJXtkoK) \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbu0b-1Zc7o4",
        "colab_type": "text"
      },
      "source": [
        "## Q4: Implementing the network\n",
        "\n",
        "All networks created with torch.nn are subclasses of nn.Module.\n",
        "\n",
        "To create our network, we need to define two methods: the init method (\"\\_\\_init\\_\\_\") and the **forward** propagation method.\n",
        "\n",
        "\n",
        "\n",
        "*   In the \"**init**\" function, we define the **parts** (layers) of the network we are going to use and store them as attributes \n",
        "*   In the \"**forward**\" function, we define the **order** of the layers by applying them to an input (define-by-run)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Fill the code below** so that it corresponds to the architecture represented above. Please note that **there is a \"ReLu\" activation after every convolutional and linear (fully connected) layer in this architecture, that is not pictured.**\n",
        "\n",
        "The torch.nn documentation will probably be useful https://pytorch.org/docs/stable/nn.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9FqAeK9mhar",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "class MyFirstNetwork(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(MyFirstNetwork, self).__init__()\n",
        "    \n",
        "    ## MNIST images are 28x28 but LeNet5 expects 32x32\n",
        "    ## -> we pad the images with zeroes\n",
        "    self.padding = nn.ZeroPad2d(2)\n",
        "    \n",
        "    ## First convolution\n",
        "    self.conv1 = nn.Conv2d(in_channels = 1, out_channels= 5 , kernel_size = 5)\n",
        "    \n",
        "    ## Second convolution\n",
        "    self.conv2 = ## YOUR CODE HERE\n",
        "    \n",
        "    ## Pooling (subsampling) layer\n",
        "    self.maxpool = nn.MaxPool2d(2)\n",
        "    \n",
        "    ## Activation layer\n",
        "    self.relu = nn.ReLU()\n",
        "    \n",
        "    ## Fully connected layers\n",
        "    self.fc1 = nn.Linear(in_features = 400, out_features = 120)\n",
        "    self.fc2 = ## YOUR CODE HERE\n",
        "    self.output = ## YOUR CODE HERE\n",
        "    \n",
        "    ## Final activation layer\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    \n",
        "    ## Pad the input\n",
        "    x = self.padding(x)\n",
        "    \n",
        "    ## First convolution + activation\n",
        "    x = self.conv1(x)\n",
        "    x = self.relu(x)\n",
        "    \n",
        "    ## First pooling\n",
        "    x = self.maxpool(x)\n",
        "    \n",
        "    ## Second Convolution + activation\n",
        "    \n",
        "    ## YOUR CODE HERE\n",
        "    \n",
        "    ## Second Pooling\n",
        "    \n",
        "    ## YOUR CODE HERE\n",
        "    \n",
        "    ## \"Flatten\" the output to make it 1D\n",
        "    x = x.view(-1, 16*5*5)\n",
        "    \n",
        "    ## First full connection\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu(x)\n",
        "    \n",
        "    ## Second full connection\n",
        "    \n",
        "    ## YOUR CODE HERE\n",
        "    \n",
        "    ## Output layer\n",
        "    x = self.output(x)\n",
        "    y = self.softmax(x)\n",
        "    \n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6Vo_6yRc26m",
        "colab_type": "text"
      },
      "source": [
        "### Testing our implementation\n",
        "\n",
        "To check that the network is working and possibly correct mistakes, we apply the forward method to an image from the MNIST dataset. \n",
        "\n",
        "**Check that your network is working by running the code below.**\n",
        "\n",
        "At any point in the forward pass, you can execute Python code allowing you to debug the network. This is one of the main benefits of using PyTorch. This framework has \"eager execution\", and the architecture is \"defined-by-run\". Other frameworks, such as Tensorflow, compile the network into a fixed graph that cannot be debugged using prints.\n",
        "\n",
        "PyTorch works on objects called **Tensors**, which are N-dimensional matrices.\n",
        "\n",
        "Tensors can be displayed using the Python '**print**' function, their size can be accessed using **x.size()**, etc.\n",
        "\n",
        "See the PyTorch documentation for other operations on Tensors https://pytorch.org/docs/stable/tensors.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMxl2UlBdJUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Create an instance of our network\n",
        "net = MyFirstNetwork()\n",
        "\n",
        "## Create a conversion function to convert PIL images into Tensors\n",
        "convert = torchvision.transforms.ToTensor()\n",
        "\n",
        "## Get our input image as a tensor. We add a dimension with \"unsqueeze\", because\n",
        "## PyTorch is used to working with batches.\n",
        "x = convert(mnist_dataset[0][0]).unsqueeze(0)\n",
        "\n",
        "## Apply the network to the input\n",
        "net(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3BQubKSwfJb",
        "colab_type": "text"
      },
      "source": [
        "The result should be a 10-dimensional vector (tensor) of probabilities. If your network does not work, edit it and try again!\n",
        "\n",
        "NOTE: You can notice a \"LogSoftmaxBackward\" object. PyTorch automatically tracks which operations have been performed on Tensors, so that it can perform automatic gradient computation during training. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKz1p2jLkEpO",
        "colab_type": "text"
      },
      "source": [
        "#  Part 3: Training the network\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InctrLEkjcMX",
        "colab_type": "text"
      },
      "source": [
        "## Choosing a loss function and an optimizer\n",
        "\n",
        "As a Loss, the negative log likelihood (also called cross-entropy) is well suited here, because we have an N-class classification problem.\n",
        "\n",
        "Stochastic Gradient Descent is the most basic optimization algorithm. You can try to use another one from torch.optim (https://pytorch.org/docs/stable/optim.html). You can also try to adjust the learning rate (lr parameter)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lZPjeAKjaKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Negative log likelihood loss\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Stochastic Gradient Descent\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYIvxuq5zMWL",
        "colab_type": "text"
      },
      "source": [
        "## Basic training bricks\n",
        "\n",
        "There are 4 parts to train the network on one sample of the dataset:\n",
        "\n",
        "\n",
        "\n",
        "1.   Compute the forward pass\n",
        "\n",
        "```\n",
        "    y = net(x)\n",
        "```\n",
        "\n",
        "\n",
        "2.   Compute the loss\n",
        "\n",
        "\n",
        "```\n",
        "    loss = criterion(y, label)\n",
        "```\n",
        "\n",
        "\n",
        "3.   Reset the gradients\n",
        "\n",
        "\n",
        "```\n",
        "    optimizer.zero_grad()\n",
        "```\n",
        "\n",
        "\n",
        "4.   Compute the backward pass\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "     loss.backward()\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "5.   Apply one optimization step\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "     optimizer.step()\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kvwV7HAkz1b",
        "colab_type": "text"
      },
      "source": [
        "## Q5: Creating a basic training loop\n",
        "\n",
        "Neural Networks are trained using training loops. We go over the dataset multiple times (each time is called an \"epoch\"), using \"batches\" of data.\n",
        "\n",
        "First, we are going to create the most basic training loop possible, going over the dataset manually using a batch size of 1 (the network sees the images one by one). Every time an image goes through the network, we compute the loss and the gradients and update the network weights.\n",
        "\n",
        "**Fill the code below using the basic training bricks above to create the training loop.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2TU7F3VXUDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## MODIFY THIS LINE IF THE TRAINING TAKES TOO LONG (MAX 60000)\n",
        "SAMPLES_TO_USE = 1000\n",
        "\n",
        "## NUMBER OF EPOCHS TO TRAIN\n",
        "N_EPOCHS = 5\n",
        "\n",
        "## Put the network in training mode\n",
        "net.train()\n",
        "\n",
        "for e in tqdm_notebook(range(N_EPOCHS), desc='Epochs'):\n",
        "  \n",
        "  running_loss = 0\n",
        "  running_accuracy = 0\n",
        "  \n",
        "  for i in tqdm_notebook(range(SAMPLES_TO_USE), desc=\"Samples\"):\n",
        "    \n",
        "    # Get a sample from the dataset\n",
        "    sample = mnist_dataset[i]\n",
        "    x = convert(sample[0]).unsqueeze(0)\n",
        "    label = torch.tensor([sample[1]])\n",
        "    \n",
        "    ###\n",
        "    ### YOUR CODE HERE\n",
        "    ###\n",
        "    \n",
        "    ## Compute some statistics\n",
        "    with torch.no_grad():\n",
        "      running_loss += loss.data\n",
        "      running_accuracy += 1 if y.max(1)[1] == label else 0\n",
        "    \n",
        "  print(\"Training accuracy:\", running_accuracy/SAMPLES_TO_USE)\n",
        "  print(\"Training loss:\", running_loss/SAMPLES_TO_USE)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZWWnfPIsCbq",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating on a test set\n",
        "\n",
        "While performance on the training set might be good (you can reach 100% accuracy in this example), what really matters is performance on the test set. The test set is composed of images the network has never seen before.\n",
        "\n",
        "**Run the following code to evaluate your network.** Make sure that you reach at least approximately 90% test accuracy before moving on to the next part!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRelqgPssVrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get the MNIST test set\n",
        "mnist_test_dataset = torchvision.datasets.MNIST(\".\", train=False, transform=convert, download=True)\n",
        "\n",
        "print(\"Number of test images:\", len(mnist_test_dataset))\n",
        "\n",
        "#Put the network in eval mode\n",
        "net.eval()\n",
        "\n",
        "acc = 0\n",
        "#Disable gradient computation for this (we do not need them, this will speed up testing)\n",
        "with torch.no_grad():\n",
        "  for img, label in tqdm_notebook(mnist_test_dataset):\n",
        "\n",
        "    y = net(img.unsqueeze(0))\n",
        "\n",
        "    if y.max(1)[1] == label:\n",
        "      acc +=1\n",
        "\n",
        "  print(\"Test Accuracy:\", acc/len(mnist_test_dataset))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPjWzrzcnNo-",
        "colab_type": "text"
      },
      "source": [
        "## Q6: Displaying a few random results from the test set\n",
        "\n",
        "Let's look at some results, to visualize in which cases our network makes mistakes.\n",
        "\n",
        "Using Python's **random** package and your trained neural network, display 10 results from the test set.\n",
        "\n",
        "HINT: to get the network output for a sample as a number, you can use: \n",
        "\n",
        "```\n",
        "    net(convert(sample[0]).unsqueeze(0)).max(1)[1]\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxLkndAYnqwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "mnist_test_dataset_PIL = torchvision.datasets.MNIST(\".\", train=False, download=True)\n",
        "\n",
        "for i in range(10):\n",
        "  ### YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on5O7Ihdwt3r",
        "colab_type": "text"
      },
      "source": [
        "# Part 4: Creating a better training loop\n",
        "\n",
        "Our basic training method works, but as you might have noticed it is pretty slow.\n",
        "In this section, we improve it to create a \"good\" PyTorch training loop, by using batches, data loaders, validation data, and GPUs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQjrMBqHw20t",
        "colab_type": "text"
      },
      "source": [
        "## Splitting between validation and training data\n",
        "\n",
        "It is common to split the training dataset into a training set and a validation set. \n",
        "\n",
        "The network is trained on the training set, and its performance is validated at each epoch using the validation set.\n",
        "\n",
        "This is used to prevent overfitting. If the training accuracy/loss improves but the validation accuracy/loss stagnate or worsen we are **overfitting** the training set.\n",
        "\n",
        "The final evaluation is still done on the test set.\n",
        "\n",
        "![Texte alternatif…](https://miro.medium.com/max/1552/1*Nv2NNALuokZEcV6hYEHdGA.png)\n",
        "\n",
        "This is very easy in PyTorch. Let's split our MNIST **Dataset** into two random **Subsets** (it's a subclass of **Dataset**)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W1GXJ09_7S0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Load Dataset\n",
        "mnist_dataset = torchvision.datasets.MNIST(\".\", train=True, transform=convert, download=True)\n",
        "\n",
        "## Percentage of validation data\n",
        "validation_split = 0.1\n",
        "\n",
        "N_val_samples = round(validation_split * len(mnist_dataset))\n",
        "\n",
        "## Split into two Subset\n",
        "train_set, val_set = torch.utils.data.random_split(mnist_dataset, [len(mnist_dataset) - N_val_samples, N_val_samples])\n",
        "\n",
        "# train and val are Subset objects\n",
        "print(train_set)\n",
        "print(val_set)\n",
        "\n",
        "# Their sizes should be correct\n",
        "len(train_set) + len(val_set) == len(mnist_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJxljKdjxkcm",
        "colab_type": "text"
      },
      "source": [
        "## DataLoaders in PyTorch\n",
        "\n",
        "In PyTorch, **DataLoaders** are tools that load **batches** of data from a **Dataset** (or any of its subclasses).\n",
        "\n",
        "Training in batches of multiple samples (8, 32, 512...) can be a lot faster thanks to parallelism. Also, it helps with gradient descent by averaging the gradient over the whole batch.\n",
        "\n",
        "Documentation on DataLoaders is here: https://pytorch.org/docs/stable/data.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0zPFABa8ATU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## This line creates a basic DataLoader from our mnist training set\n",
        "\n",
        "## You can change options such as batch size, shuffling, number of workers...\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "mnist_train_dl = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baGmNj1l8kJ5",
        "colab_type": "text"
      },
      "source": [
        "## Q7: Use the DataLoaders\n",
        "\n",
        "Using the DataLoader we just created, **print the number of batches it contains (you should see len(train_set)/batch_size), and print a batch from the dataset.**\n",
        "\n",
        "HINT: you can get a Python iterator from a DataLoader using the **iter** function, because a DataLoader is an **iterable** object. https://wiki.python.org/moin/Iterator\n",
        "\n",
        "You should see a number of samples and labels equal to your batch size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJT3P6B386cS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Print the length of the dataloader\n",
        "\n",
        "### YOUR CODE HERE\n",
        "\n",
        "## Print a batch\n",
        "\n",
        "### YOUR CODE HERE\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10sQTysRYSo8",
        "colab_type": "text"
      },
      "source": [
        "## Q8: Create a DataLoader for the validation set\n",
        "\n",
        "In the same way, **create a DataLoader for the validation set**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnGKlOWKYQzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2z0r2RSMx-Tx",
        "colab_type": "text"
      },
      "source": [
        "## Using a GPU\n",
        "\n",
        "Using a GPU in PyTorch is very easy and will make our training A LOT faster.\n",
        "\n",
        "To perform calculations on a batch on the GPU, our batch has to be moved to the GPU.\n",
        "\n",
        "To move a Tensor to the GPU memory, use the **cuda()** method.\n",
        "\n",
        "If you do not have a GPU, you will get a cuda runtime error. To add a GPU to Colab, go to Runtime -> Change Runtime Type -> Hardware Accelerator -> GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ9ICPEYZe2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = torch.Tensor(next(iter(mnist_train_dl))[0])\n",
        "\n",
        "batch = batch.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QobGMoHtb7BD",
        "colab_type": "text"
      },
      "source": [
        "You can see \"device='cuda:0'\", which means our Tensor has been moved to the first GPU in the system!\n",
        "\n",
        "Now, we also need to move our neural network to the GPU, because the computations between the network weights and the training data will happen on the GPU.\n",
        "\n",
        "For this, we also use the **cuda()** method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R48V8VJTcUbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Create an instance of our network\n",
        "net = MyFirstNetwork()\n",
        "\n",
        "## Move it to the GPU\n",
        "net = net.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnrI3i7icmGp",
        "colab_type": "text"
      },
      "source": [
        "Let's test this by computing an output on the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaOSIDZOcrdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = net(batch)\n",
        "\n",
        "print(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCFI_QT00uYp",
        "colab_type": "text"
      },
      "source": [
        "## Q9: Our new training/validation loop\n",
        "\n",
        "Now, we have all the necessary bricks to build our new improved training/validation loop!\n",
        "\n",
        "We have already written the training loop for you. Complete the validation loop!\n",
        "\n",
        "You should see that your network trains very fast on the whole training set now. One epoch should take about 10 seconds, depending on your batch size, compared to about 3 minutes on the CPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbS2h_Lmdsla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##RE-RUN THIS CODE TO GET A \"NEW\" NETWORK\n",
        "\n",
        "LEARNING_RATE = 0.001\n",
        "MOMENTUM = 0\n",
        "\n",
        "## Create an instance of our network\n",
        "net = MyFirstNetwork()\n",
        "\n",
        "## Move it to the GPU\n",
        "net = net.cuda()\n",
        "\n",
        "# Negative log likelihood loss\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Stochastic Gradient Descent\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fRq7nKkdmmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## NUMBER OF EPOCHS TO TRAIN\n",
        "N_EPOCHS = 20\n",
        "\n",
        "epoch_loss, epoch_acc, epoch_val_loss, epoch_val_acc = [], [], [], []\n",
        "\n",
        "for e in tqdm_notebook(range(N_EPOCHS), desc='Epochs'):\n",
        "  \n",
        "  \n",
        "  ### TRAINING LOOP\n",
        "  running_loss = 0\n",
        "  running_accuracy = 0\n",
        "  \n",
        "  ## Put the network in training mode\n",
        "  net.train()\n",
        "  \n",
        "  for i, batch in enumerate(tqdm_notebook(mnist_train_dl, desc=\"Training Batches\")):\n",
        "    \n",
        "    # Get a batch from the dataloader\n",
        "    x = batch[0]\n",
        "    labels = batch[1]\n",
        "    \n",
        "    # move the batch to GPU\n",
        "    x = x.cuda()\n",
        "    labels = labels.cuda()\n",
        "\n",
        "    # Compute the network output\n",
        "    y = net(x)\n",
        "    \n",
        "    # Compute the loss\n",
        "    loss = criterion(y, labels)\n",
        "    \n",
        "    # Reset the gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Compute the gradients\n",
        "    loss.backward()\n",
        "    \n",
        "    # Apply one step of the descent algorithm to update the weights\n",
        "    optimizer.step()\n",
        "    \n",
        "    ## Compute some statistics\n",
        "    with torch.no_grad():\n",
        "      running_loss += loss.item()\n",
        "      running_accuracy += (y.max(1)[1] == labels).sum().item()\n",
        "    \n",
        "  print(\"Training accuracy:\", running_accuracy/float(len(train_set)),\n",
        "        \"Training loss:\", running_loss/float(len(train_set)))\n",
        "  \n",
        "  epoch_loss.append(running_loss/len(train_set))\n",
        "  epoch_acc.append(running_accuracy/len(train_set))\n",
        "  \n",
        "  ### VALIDATION LOOP\n",
        "  ## Put the network in validation mode\n",
        "  net.eval()\n",
        "  \n",
        "  running_val_loss = 0\n",
        "  running_val_accuracy = 0\n",
        "  \n",
        "  for i, batch in enumerate(tqdm_notebook(mnist_val_dl, desc=\"Validation Batches\")):\n",
        "    \n",
        "    ### YOUR CODE HERE\n",
        "    \n",
        "    print(\"You need to write the validation loop!\")\n",
        "    break\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PQ0skf4lvB9",
        "colab_type": "text"
      },
      "source": [
        "## Q10: Making a graph with training/validation accuracy and loss\n",
        "\n",
        "You can visualize your losses and accuracies over time using matplotlib.\n",
        "\n",
        "Modify the training/val loop above to store the values (in a list), and display them in a graph.\n",
        "\n",
        "Can you spot the moment where we start to overfit the training set? \n",
        "\n",
        "Try adjusting the number of epochs, the batch size, the learning rate or changing the optimizer (add some momentum or try Adam) to get a better result on the validation set.\n",
        "\n",
        "Optimizers documentation: https://pytorch.org/docs/stable/optim.html#algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0egYTYPoBxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "### YOUR CODE HERE\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LB52Xa82lT6A",
        "colab_type": "text"
      },
      "source": [
        "## Q11: Evaluate our network on the test set (on GPU)\n",
        "\n",
        "In the same way you wrote the validation loop, create a DataLoader on the mnist test dataset, and write a test loop!\n",
        "\n",
        "You should be able to get 90% accuracy on the test set :)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwPVS-iVmSnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get the MNIST test set\n",
        "mnist_test_dataset = torchvision.datasets.MNIST(\".\", train=False, transform=convert, download=True)\n",
        "\n",
        "### WRITE THE TEST LOOP (HINT: it looks a lot like the validation loop)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wSgI6liyDUN",
        "colab_type": "text"
      },
      "source": [
        "# (OPTIONAL) Part 5: Cats vs Dogs with a torchvision network\n",
        "\n",
        "To test our skills on a new dataset, we will work on the famous Dogs vs Cats Kaggle dataset.\n",
        "\n",
        "![alt text](http://adilmoujahid.com/images/cats-dogs.jpg)\n",
        "\n",
        "\n",
        "Kaggle is a website that hosts machine learning/data science competitions. Check it out! https://www.kaggle.com/\n",
        "\n",
        "![alt text](https://miro.medium.com/max/668/1*GZrTyTz0OKMbxnO5Trhcew.png)\n",
        "\n",
        "## Downloading the data\n",
        "\n",
        "First, go to the Kaggle website and create an account.\n",
        "\n",
        "Then go to your account, click on Create New API Token - It will download kaggle.json file on your machine.\n",
        "\n",
        "Upload the kaggle.json file using this code:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VsH28HtyVb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYz7f5u122gG",
        "colab_type": "text"
      },
      "source": [
        "Download the dogs vs cats dataset using this code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1mghRYU2Pem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "! kaggle competitions download -c dogs-vs-cats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ajluLCw3F6P",
        "colab_type": "text"
      },
      "source": [
        "Extract the archives:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2PrEude3CLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! rm -rf test1 train\n",
        "\n",
        "! unzip -q train.zip\n",
        "\n",
        "! unzip -q test1.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gHvsNGB4k9D",
        "colab_type": "text"
      },
      "source": [
        "Put the data in separate directories:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vITKFz-E3gWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir train/cats\n",
        "! mkdir train/dogs\n",
        "! mv train/cat.* train/cats\n",
        "! mv train/dog.* train/dogs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVbeQPW63BVs",
        "colab_type": "text"
      },
      "source": [
        "## Q12: Load the data\n",
        "\n",
        "Using ImageFolder from torchvision (https://pytorch.org/docs/stable/torchvision/datasets.html#imagefolder), load the dataset. \n",
        "\n",
        "The training set is in the \"train\" directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zVshgAs6IvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRQ-PjUF52nF",
        "colab_type": "text"
      },
      "source": [
        "## Q13: Display a few images\n",
        "\n",
        "As before, display a few images with the **display** function. You can see that these images have varying sizes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mySnUqsM6R1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOslT3Wi96LD",
        "colab_type": "text"
      },
      "source": [
        "## Using a torchvision model\n",
        "\n",
        "torchvision has a repository of popular models ready to use for diverse computer vision tasks (classification, segmentation,...)\n",
        "\n",
        "https://pytorch.org/docs/stable/torchvision/models.html#classification\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiqMbxqi-QZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## You can change the model if you want\n",
        "net = torchvision.models.resnet18()\n",
        "\n",
        "print(net)\n",
        "\n",
        "## torchvision models are meant to be used on imagenet (1000 classes)\n",
        "## since we only have two classes, we need to modify the last layer\n",
        "\n",
        "net.fc = nn.Linear(512,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze1WstQs9UYo",
        "colab_type": "text"
      },
      "source": [
        "## Q14: Resize the images on the fly using torchvision transforms \n",
        "\n",
        "We can see from the documentation that torchvision models expect at least 244x244 images.\n",
        "\n",
        "1. Using torchvision.transforms, create a new ImageFolder dataset with on-the-fly resizing of images.\n",
        "\n",
        "2. Split this Dataset into training and validation sets, as before.\n",
        "\n",
        "3. Create a DataLoader for each set as well, just like before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXpwostGj_FX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eftQGadO_P0v",
        "colab_type": "text"
      },
      "source": [
        "## Q15: Training the model\n",
        "\n",
        "Write the training loop. You should be able to pretty much copy-paste the one from Q9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRdlDL92-ubE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LEARNING_RATE = 0.001\n",
        "\n",
        "## Move model to the GPU\n",
        "net = net.cuda()\n",
        "\n",
        "# Negative log likelihood loss\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Stochastic Gradient Descent\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px5tj6lz9RKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ukodeM5BJ9T",
        "colab_type": "text"
      },
      "source": [
        "## Q16: Test the network\n",
        "\n",
        "Compute some predictions on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6lYqRB0HOFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4olRMdTBWyb",
        "colab_type": "text"
      },
      "source": [
        "## Q17: Going further\n",
        "\n",
        "Try different networks from torchvision, and different parameters. The winner of the competition got more than 98% accuracy. How much can you get?\n",
        "\n",
        "Data augmentation (modifying your input data to make \"more\" of it) is a huge thing in deep learning. Try some techniques such as random cropping and rotation using torchvision transforms in your Dataset objects!\n",
        "\n",
        "PyTorch has a lot of tutorials to get you started: https://pytorch.org/tutorials/index.html\n",
        "\n",
        "Have fun!\n",
        "\n"
      ]
    }
  ]
}